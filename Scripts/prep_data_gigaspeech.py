# prepare data for GigaSpeech
# it uses the same train/val split as MQTTS
# it outputs val and train manifest list in Data/GigaSpeech
#
# Zhenhao Ge, 2024-05-30

import os
from pathlib import Path
import glob
import json
import librosa
import soundfile as sf
import argparse
import numpy as np
from tqdm import tqdm
import multiprocessing
import psutil
import time

# import phonemizer
import phonemizer
global_phonemizer = phonemizer.backend.EspeakBackend(
    language='en-us', preserve_punctuation=True,  with_stress=True)

# import word tokenizer
from nltk.tokenize import word_tokenize

# set paths
home_path = str(Path.home())
work_path = os.path.join(home_path, 'code', 'repo', 'style-tts2')
if os.getcwd() != work_path:
    os.chdir(work_path)
print('current path: {}'.format(os.getcwd()))

# load local modules
from text_utils import clean_text, attach_punc
from utils import set_path, tuple2csv
from Text.cleaners import collapse_whitespace, expand_abbreviations, expand_numbers

# set global variables
punc_map = {'<COMMA>':',', '<PERIOD>':'.', '<QUESTIONMARK>':'?', '<EXCLAMATIONPOINT>':'!'}
punc_list = list(punc_map.values())
sample_rate = 16000

def process_text(text, punc_map):
    for k,v in punc_map.items():
        text = text.replace(k, v)
    text = text.lower()
    return text

def get_sid2path(sid2path_file, verbose=False):

    # read sid2path file
    lines = open(sid2path_file, 'r').readlines()
    lines = [line for line in lines if line.strip() != '']
    num_lines = len(lines)
    if verbose:
        print(f'# of lines in {sid2path_file}: {num_lines}')

    # parse info to sid2path dict
    sid2path = {}
    for i, line in enumerate(lines):
        sid, wav_rel_path = line.strip().split('|')
        sid2path[sid] = wav_rel_path

    return sid2path

def get_fid2meta(sid, sid2path, data_path):
    """get meta info from sid/fid"""

    audio_path = os.path.join(data_path, 'audio')
    meta_path = os.path.join(data_path, 'metadata')

    # get wav, text and meta json paths
    wav_rel_path = sid2path[sid]
    wav_path = os.path.join(data_path, wav_rel_path)
    txt_path = wav_path.replace('.wav', '.txt')
    json_path = wav_path.replace('.wav', '.json')

    # check if wav path is valid
    cond11 = os.path.isfile(wav_path)
    if cond11:
        dur = librosa.get_duration(filename=wav_path)
        cond12 = dur> 1.0
    else:
        cond12 = False
    cond1 = cond11 and cond12

    # check if text path is valid
    cond21 = os.path.isfile(txt_path)
    if cond21:
        lines = open(txt_path, 'r').readlines()
        nlines = len(lines)
        cond22 = nlines == 1
    else:
        cond22 = False
    cond2 = cond21 and cond22

    # check if json path is valid
    cond31 = os.path.isfile(json_path)
    if cond31:
        nlines_json = len(open(json_path, 'r').readlines())
        cond32 = nlines_json > 0
    else:
        cond32 = False
    cond3 = cond31 and cond32

    # get text and meta
    if cond1 and cond2 and cond3:

        print(f'sid {sid} already completed, reading segment ...')

        # read text
        text_tn = open(txt_path, 'r').readlines()
        text_tn = text_tn[0].strip()

        # read meta
        with open(json_path) as f:
            meta = json.load(f)

    else:

        print(f'sid {sid} is not completed, generating segment ...')

        # get audio file
        parts = wav_rel_path.split(os.sep)
        cat, pid, aid = parts[1:4]
        audio_file = os.path.join(audio_path, cat, pid, f'{aid}.wav')
        assert os.path.isfile(audio_file), f'audio file {audio_file} does not exist!'

        # load audio dict from meta file (generated by segment_audio_gigaspeech.py)
        meta_file = os.path.join(meta_path, cat, pid, f'{aid}.json')
        assert os.path.isfile(meta_file), f'meta file {meta_file} does not exist!'
        with open(meta_file, 'r') as f:
            audio_dict = json.load(f)

        # get segment for current sid
        segments = audio_dict['segments']
        segment = [seg for seg in segments if seg['sid'] == sid]
        assert len(segment) == 1, f'segment does not found!'
        segment = segment[0]

        # get info from segment
        begin_time = segment['begin_time']
        end_time = segment['end_time']
        duration = round(end_time - begin_time, 3)
        text_tn = segment['text_tn']
        text_tn = process_text(text_tn, punc_map)

        # read in the audio segment
        y, sr = librosa.load(audio_file, sr=sample_rate, offset=begin_time, duration=duration)

        # save segment wav file
        wav_dir = os.path.dirname(wav_path)
        os.makedirs(wav_dir, exist_ok=True)
        sf.write(wav_path, y, sr)

        # save segment text file
        with open(txt_path, 'w') as f:
            f.write(f'{text_tn}\n')

        # save segment json file
        meta = {'title': audio_dict['title'], 'pid': pid, 'aid': aid, 'sid': sid, 'speaker': segment['speaker'],
                'begin_time': begin_time, 'end_time': end_time, 'duration': duration, 'subsets': segment['subsets']}
        with open(json_path, 'w') as f:
            json.dump(meta, f, indent=2)

    # futher process text_tn and get text (in the format that is required by style-tts2)
    text_tn = attach_punc(text_tn, punc_list)
    text_tn = text_tn.replace('-', ' ')
    text_tn = collapse_whitespace(text_tn)
    text_tn = expand_abbreviations(text_tn)
    text = clean_text(text_tn, replace_word=False, flag_ascii=False, flag_lowercase=False)
    if text != text_tn:
        raise Exception(f'text: {text}, text_tn: {text_tn}')

    return {'text': text, 'duration': meta['duration'], 'speaker': meta['aid']}

def worker(sids_split, sid2path, data_path, return_dict):
    """worker wrapper over get_fid2meta"""
    for sid in sids_split:
        return_dict[sid] = get_fid2meta(sid, sid2path, data_path)

def get_manifest(fids, fid2meta, use_spkr=True, use_dur=True, spkr_id=0):
    """get the manifest tuple list (check fid in fids and fid2text to ensure they are match
       either real fid, or rel path"""

    num_fids = len(fids)
    tuple_list = [() for _ in range(num_fids)]
    for i in range(num_fids):

        fid = fids[i]

        # get meta from fid2meta (fid is wav rel path)
        meta = fid2meta[fid]

        # get text from meta
        text = meta['text']

        # get the raw IPA phone seqs
        ps = global_phonemizer.phonemize([text])[0]

        # split the raw IPA phones to words
        ps1 = word_tokenize(ps)

        # join with space
        # (compared with ps, the punctuations are now separated from the adjacent word)
        ps2 = ' '.join(ps1)

        if 'speaker' in meta.keys() and use_spkr:
            spkr_id = meta['speaker']
        if 'duration' in meta.keys() and use_dur:
            dur = meta['duration']
            tuple_list[i] = (fid, text, ps2, dur, spkr_id)
        else:
            tuple_list[i] = (fid, text, ps2, spkr_id)

    return tuple_list

def get_manifest_single(fid, fid2meta, use_spkr=True, use_dur=True, spkr_id=0):
    """get the manifest tuple element (check fid in fids and fid2text to ensure they are match
       either real fid, or rel path"""

    # get meta from fid2meta (fid is wav rel path)
    meta = fid2meta[fid]

    # get text from meta
    text = meta['text']

    # get the raw IPA phone seqs
    ps = global_phonemizer.phonemize([text])[0]

    # split the raw IPA phones to words
    ps1 = word_tokenize(ps)

    # join with space
    # (compared with ps, the punctuations are now separated from the adjacent word)
    ps2 = ' '.join(ps1)

    if 'speaker' in meta.keys() and use_spkr:
        spkr_id = meta['speaker']
    if 'duration' in meta.keys() and use_dur:
        dur = meta['duration']
        tuple_element = (fid, text, ps2, dur, spkr_id)
    else:
        tuple_element = (fid, text, ps2, spkr_id)

    return tuple_element

def worker2(fids_split, fid2meta, return_dict, use_spkr=True, use_dur=True):
    """worker wraper over get_manifest_single"""
    for fid in fids_split:
        return_dict[fid] = get_manifest_single(fid, fid2meta, use_spkr=use_spkr, use_dur=use_dur)

def map_sid(sids, bs=10000):
    """map sids to aid:[uids] where each sid is <aid>_<uid>"""

    num_sids = len(sids)

    # construct aid2uids from sids
    aid2uids = {}
    for i, sid in enumerate(sids):

        if i % bs == 0:
            print(f'processing {i} to {min(i+bs, num_sids)} ...')

        aid, uid = sid.split('_')
        if aid in aid2uids.keys():
            aid2uids[aid].append(uid)
        else:
            aid2uids[aid] = [uid]

    # get aids
    aids = sorted(aid2uids.keys())

    # sort uids per aid in aid2uids
    uid_cnt = {}
    for aid in aids:
        uids = aid2uids[aid]
        uid_cnt[aid] = len(uids)
        aid2uids[aid] = sorted(uids)
    num_uids = sum([v for v in uid_cnt.values()])
    assert num_uids == num_sids, f'#sids is {num_sids}, but only {num_uids} are processed!'

    return aid2uids

def find_sids_rest(sids_sel, sids_done):
    """find sids that is in sids_sel, but not in sids_done
       this is much faster than [sid for sid in sids_sel if sid not in sids_done]"""

    num_sids_sel = len(sids_sel)
    num_sids_done = len(sids_done)
    num_sids_rest = num_sids_sel - num_sids_done
    print(f'#sids total selected: {num_sids_sel}, #sids done: {num_sids_done}')

    # convert sids to aid2uids
    aid2uids_sel = map_sid(sids_sel)
    aid2uids_done = map_sid(sids_done)

    # find aid2uids_rest
    aid2uids_rest = {}
    for aid in aid2uids_sel.keys():
        if aid in aid2uids_done:
            for uid in aid2uids[aid]:
                if uid not in aid2uids_done[aid]:
                    if aid not in aid2uids_rest.keys():
                        aid2uids_rest[aid] = [uid]
                    else:    
                        aid2uids_rest[aid].append(uid)
        else:
            aid2uids_rest[aid] = aid2uids_sel[aid]

    # convert aid2uids_rest to sids_rest
    sids_rest = []
    for aid in aid2uids_rest.keys():
        for uid in aid2uids_rest[aid]:
            sid = f'{aid}_{uid}'
            sids_rest.append(sid)
    num_sids_rest2 = len(sids_rest)

    # sanity check: if all remaining sids are obtained
    assert num_sids_rest2 == num_sids_rest, \
        f'#sids remaining is {num_sids_rest}, but only {num_sids_rest2} are obtained!'

    return sids_rest

def parse_args():
    usage = 'usage: prepare the GigaSpeech data for the StyleTTS training'
    parser = argparse.ArgumentParser(description=usage)
    parser.add_argument('--data-path', type=str, help='data root path')
    parser.add_argument('--sid-filepath', type=str, help='reference file to get ids')
    parser.add_argument('--out-filepath', type=str, help='output manifest file path')
    return parser.parse_args()

if __name__ == '__main__':

    # runtime mode
    args = parse_args()

    # # interactive mode
    # args = argparse.ArgumentParser()

    # args.data_path = os.path.join(work_path, 'Datasets', 'GigaSpeech-Zhenhao')
    # args.sid2path_file = os.path.join(args.data_path, 'sid2path.txt')

    # # validation
    # args.sid_file = os.path.join(home_path, 'code', 'repo', 'mqtts', 'datasets_ori', 'validation.txt')
    # args.out_filepath = os.path.join(work_path, 'Data', 'GigaSpeech', 'val_list.txt')

    # # training
    # args.sid_file = os.path.join(home_path, 'code', 'repo', 'mqtts', 'datasets_ori', 'training.txt')
    # args.out_filepath = os.path.join(work_path, 'Data', 'GigaSpeech', 'train_list.txt')

    # localize arguments
    data_path = args.data_path
    sid_file = args.sid_file
    sid2path_file = args.sid2path_file
    out_filepath = args.out_filepath
    cat = os.path.splitext(os.path.basename(out_filepath))[0].split('_')[0]

    # set output path
    out_dir = os.path.dirname(out_filepath)
    set_path(out_dir, verbose=True)

    # set audio path (contain the orginal audio files before sentence segmentation)
    audio_path = os.path.join(data_path, 'audio')
    assert os.path.isdir(audio_path), f'audio path: {audio_path} does not exist!'

    # set meta path
    meta_path = os.path.join(data_path, 'metadata')
    assert os.path.isdir(meta_path), f'meta path: {meta_path} does not exist!'

    # get sid2path dict (#sids: 8315357)
    sid2path = get_sid2path(sid2path_file)
    num_sids = len(sid2path)
    print(f'# of sids: {num_sids}')

    # read sid list (from MQTTS version)
    lines = open(sid_file, 'r').readlines()
    sids_sel = [line.strip() for line in lines]
    num_sids_sel = len(sids_sel)
    sel_perc = num_sids_sel / num_sids

    # print the #sids selected and its segment-wise percentage, train: 498172 (5.991%), val: 1472 (0.018%)
    print(f'# of sids selected: {num_sids_sel}/{num_sids} ({sel_perc*100:.3f}%)')

    # # (optional) check # of segment files generated (from segment_audio_gigaspeech.py)
    # seg_paths = glob.glob(os.path.join(data_path, 'segment', '**', '*.wav'), recursive=True)
    # print(f'# of segment files generated: {len(seg_paths)}') # 4678819

    # get fid2meta (with nprocs threads)
    start_time = time.time()
    nprocs = psutil.cpu_count()
    manager = multiprocessing.Manager()
    return_dict = manager.dict()
    jobs = []
    sids_group = np.array_split(sids_sel, nprocs)
    for i in range(nprocs):
        p = multiprocessing.Process(target=worker, args=(list(sids_group[i]), sid2path, data_path, return_dict))
        jobs.append(p)
        p.start()
    for proc in jobs:
        proc.join()
    sid2meta = return_dict
    end_time = time.time()
    elapsed_time = end_time - start_time
    # duration of multithreads processing: 5.94 seconds (val), 0.63 hrs. (train)
    print('duration of processing fid2meta with multithreads: {:.2f} seconds'.format(elapsed_time))

    # fid2meta = {sid2path[sid]:sid2meta[sid] for sid in sids_sel}
    fid2meta = {sid2path[sid]:meta for (sid,meta) in sid2meta.items()}

    # # get fid2meta (with single thread)
    # start_time = time.time()
    # fid2meta = {}
    # for sid in tqdm(sids_sel):
    #     fid = sid2path[sid]
    #     fid2meta[fid] = get_fid2meta(sid, sid2path, data_path)
    # end_time = time.time()
    # elapsed_time = end_time - start_time
    # # duration of single-thread processing: 39 seconds (val)
    # print('duration of processing fid2meta with single thread: {:.2f} seconds'.format(elapsed_time))

    # # get backup fid2meta (read from local)
    # fid2meta_jsonfile = os.path.join(data_path, f'fid2meta_{cat}.json')
    # if os.path.isfile(fid2meta_jsonfile):
    #     with open(fid2meta_jsonfile, 'r') as f:
    #         fid2meta = json.load(f)
    # else:
    #     fid2meta_jsonfile = os.path.join(data_path, f'fid2meta_{cat}_partial.json')
    #     with open(fid2meta_jsonfile, 'r') as f:
    #         fid2meta = json.load(f)

    # write fid2meta partial json file for backup
    fid2meta_jsonfile = os.path.join(data_path, f'fid2meta_{cat}_partial.json')
    with open(fid2meta_jsonfile, 'w') as f:
        json.dump(fid2meta, f, indent=2)
    print(f'fi2meta partial json file: {fid2meta_jsonfile}')

    # find fids from selected sids
    fids_sel = [sid2path[sid] for sid in sids_sel]
    num_fids_sel = len(fids_sel)

    # sanity check: if all fids (or sids) are processed
    fids_done = sorted(fid2meta.keys())
    sids_done = [os.path.splitext(os.path.basename(fid))[0] for fid in fids_done]
    num_sids_done = len(sids_done)
    print(f'#sids total selected: {num_sids_sel}, #sids done: {num_sids_done}')

    # backup processing to get imcompleted fid2meta if there are some fids left imcompleted
    fid2meta_rest = {}
    if num_sids_done < num_sids_sel:
        sids_rest = find_sids_rest(sids_sel, sids_done)
        # sids_rest = [sid for sid in sids_sel if sid not in sids_done] # this is very slow
        num_sids_rest = len(sids_rest)
        for i, sid in enumerate(tqdm(sids_rest)):
            fid = sid2path[sid]
            fid2meta_rest[fid] = get_fid2meta(sid, sid2path, data_path)
    else:
        print(f'{num_fids_sel} fids for category {cat} are all processed.')

    # merge fid2meta_rest to fid2meta if fid2meta_rest is not empty
    if fid2meta_rest:
        for fid in fid2meta_rest.keys():
            fid2meta[fid] = fid2meta_rest[fid]

    # sanity check: all fids (or sids) are processed
    fids_done = sorted(fid2meta.keys())
    sids_done = [os.path.splitext(os.path.basename(fid))[0] for fid in fids_done]
    num_sids_done = len(sids_done)
    assert num_sids_done == num_sids_sel, f'#sids total selected: {num_sids_sel}, #sids done: {num_sids_done}'

    # write fid2meta json file
    fid2meta_jsonfile = os.path.join(data_path, f'fid2meta_{cat}.json')
    with open(fid2meta_jsonfile, 'w') as f:
        json.dump(fid2meta, f, indent=2)
    print(f'fi2meta json file: {fid2meta_jsonfile}')

    # get the manifest tuple list (with nprocs threads)
    start_time = time.time()
    nprocs = psutil.cpu_count()
    manager = multiprocessing.Manager()
    return_dict = manager.dict()
    jobs = []
    # fids_group = np.array_split(fids_sel[:1000], nprocs) # test
    fids_group = np.array_split(fids_sel, nprocs)
    use_spkr, use_dur = False, False
    for i in range(nprocs):
        p = multiprocessing.Process(target=worker2, args=(list(fids_group[i]), fid2meta, return_dict, use_spkr, use_dur))
        jobs.append(p)
        p.start()
    for proc in jobs:
        proc.join()
    fid2tuple = return_dict
    tuple_list = [fid2tuple[fid] for fid in fids_sel]
    end_time = time.time()
    elapsed_time = end_time - start_time
    print('duration of processing manifest tuple with multithreads: {:.2f} seconds'.format(elapsed_time)) # take about 2 minutes

    # # get the manifest tuple list (with single thread)
    # tuple_list = get_manifest(fids_sel, fid2meta, use_spkr=False, use_dur=False)

    # sanity check: tuple list contains all the fids
    num_fids_proc = len(tuple_list)
    assert num_fids_proc == num_fids_sel, f'tuple list contains {num_fids_proc}/{num_fids_sel} fids!'

    # write output manifest file
    tuple2csv(tuple_list, out_filepath, delimiter='|')

    # get some stats for the maniefst file
    speakers = sorted(set([meta['speaker'] for fid, meta in fid2meta.items()]))
    durations = [meta['duration'] for fid, meta in fid2meta.items()]
    stats = {'num-fids': num_sids_sel,
            'num-speakers': len(speakers),
            'dur-total-hrs': round(np.sum(durations)/3600, 2),
            'dur-mean-secs': round(np.mean(durations), 2)}

    # print the statistics
    # val: num_fids (1472), num_speakers (24), dur_total_hrs (3.59), dur_mean_secs (8.78)
    # train: num_fids (498172), num_speakers (22699), dur_total_hrs (1063.48), dur_means_sec (7.69)
    for k,v in stats.items():
        if isinstance(v, np.floating):
            print(f'{k}: {v:.2f}')
        else:
            print(f'{k}: {v}')

    # write the statistics to a json file
    out_jsonfile = out_filepath.replace('.txt', '.json')
    with open(out_jsonfile, 'w') as f:
        json.dump(stats, f, sort_keys=True, indent=2)
    print(f'wrote {out_jsonfile}')
